{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Lab: Grid Search with MLflow\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you:<br>\n - Create a new MLfow experiment\n - Perform grid search using Scikit-Learn\n - Log the best model on MLflow\n - Load the saved model"],"metadata":{}},{"cell_type":"markdown","source":["## Creating New MLflow Experiment\n\nComplete the `experimentPath` code below to create a brand new experiment under your user folder named `02-Lab-GridSearch`.\n\nOpen this experiment's MLflow UI in a different tab afterwards."],"metadata":{}},{"cell_type":"code","source":["%run \"./../Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Load in same Airbnb data and create train/test split."],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"/dbfs/mnt/training/airbnb/sf-listings/airbnb-cleaned-mlflow.csv\")\nX_train, X_test, y_train, y_test = train_test_split(df.drop([\"price\"], axis=1), df[[\"price\"]].values.ravel(), random_state=42)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["## Perform Grid Search using Scikit-Learn\n\nWe want to know which combination of hyperparameter values is the most effective. Fill in the code below to perform <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\" target=\"_blank\"> grid search using `sklearn`</a> over the 2 hyperparameters we looked at in the 02 notebook, `n_estimators` and `max_depth`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\nimport mlflow.sklearn\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# dictionary containing hyperparameter names and list of values we want to try\nparameters = {'n_estimators':[100,1000], \n              'max_depth':[10,15]}\n\nrf = RandomForestRegressor()\ngrid_rf_model = GridSearchCV(rf, parameters, cv=3)\ngrid_rf_model.fit(X_train, y_train)\n\nbest_rf = grid_rf_model.best_estimator_\nfor p in parameters:\n  print(\"Best '{}': {}\".format(p, best_rf.get_params()[p]))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Log Best Model on MLflow\n\nLog the best model as `grid-random-forest-model`, its parameters, and its MSE metric under a run with name `RF-Grid-Search` in our new MLflow experiment."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\nfrom sklearn.metrics import mean_squared_error\n\nwith mlflow.start_run(run_name=\"RF-Grid-Search\") as run:\n  # Create predictions of X_test using best model\n  predictions = best_rf.predict(X_test)\n  \n  # Log model\n  mlflow.sklearn.log_model(best_rf, \"grid-random-forest-model\")\n  \n  # Log params\n  model_params = best_rf.get_params()\n  [mlflow.log_param(p, model_params[p]) for p in parameters]\n  \n  # Create and log MSE metrics using predictions of X_test and its actual value y_test\n  mse = mean_squared_error(y_test, predictions)\n  mlflow.log_metric(\"mse\", mse)\n  \n  runID = run.info.run_uuid\n  print(\"Inside MLflow Run with id {}\".format(runID))"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Check on the MLflow UI that the run `RF-Grid-Search` is logged has the best parameter values found by grid search."],"metadata":{}},{"cell_type":"markdown","source":["## Load the Saved Model\n\nFill in the `path` and `run_id` to load the trained and tuned model we just saved. Check that the hyperparameters of this model matches that of the best model we found earlier!"],"metadata":{}},{"cell_type":"code","source":["# ANSWER\nloaded_model = mlflow.sklearn.load_model(path=\"grid-random-forest-model\", run_id=runID)\nloaded_model"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["Time permitting, continue to grid search over a wider number of parameters and automatically save the best performing parameters back to `mlflow`."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2019 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"02-Lab","notebookId":1121904905106333},"nbformat":4,"nbformat_minor":0}
