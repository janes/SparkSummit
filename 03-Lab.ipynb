{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Lab: Running a Project within a Project\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you:<br>\n- Check directory for appropriate files\n- Create and run a driver-less workflow"],"metadata":{}},{"cell_type":"code","source":["%run \"./../Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["-sandbox\n## Check for Appropriate Files\n\nThis lab will reuse your work from lesson 3.  Run the following 2 cells to check that your `/user/ < username > /ml-production` folder still contains the files created and saved in the 03 notebook.\n\nUnder `train_path`, you should have the following 3 files: \n* `MLproject`\n* `conda.yaml`\n* `train.py`\n\nUnder `load_path`, you should have the following 3 files: \n* `MLproject`\n* `conda.yaml`\n* `load.py`\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> If these files are not present, [re-run Lesson 3.]($../03-Packaging-ML-Projects )"],"metadata":{}},{"cell_type":"code","source":["train_path = userhome + \"/ml-production/mlflow-model-training/\"\n\ndbutils.fs.ls(train_path)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["load_path = userhome + \"/ml-production/mlflow-data-loading/\"\n\ndbutils.fs.ls(load_path)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["-sandbox\n## Create a Driver-less Workflow\n\nAt the end of notebook 3, we retrieved the data path artifact saved from the data loading run and used that as the `data_path` parameter of our training code. We did this by making two separate calls to `mlflow.projects.run`.\n\n<div><img src=\"https://files.training.databricks.com/images/eLearning/ML-Part-4/mlproject-architecture3.png\" style=\"height: 250px; margin: 20px\"/></div>\n\nNow we want log the same projects but through **only 1 explicit `mlflow.projects.run` call.**  In other words, the first project should call the second project:<br><br>\n\n1. Edit the following `data_load` function to take in `train_path` as an additional parameter \n2. Call the MLproject saved at `train_path` as its last step"],"metadata":{}},{"cell_type":"code","source":["# ANSWER\nimport mlflow\n\ndef data_load(data_input_path, train_path):\n\n  with mlflow.start_run() as run:\n    # Log the data\n    mlflow.log_artifact(data_input_path, \"data-csv-dir\")\n  mlflow.projects.run(\n    uri=train_path,\n    parameters={ \"data_path\": data_input_path}\n    )\n\nif __name__ == \"__main__\":\n  data_load( \"/dbfs/mnt/training/airbnb/sf-listings/airbnb-cleaned-mlflow.csv\", train_path.replace(\"dbfs:\", \"/dbfs\"))"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Double check that the UI correctly logged your 2 project runs (the data loading and then training) from above by comparing it to the last 2 runs from the end of the 03 notebook.\n\nThen fill in the below code to overwrite the original `load.py` file to have the new `data_load(data_input_path, train_path)` function. Be sure to add an appropriate `@click.option` for the new `train_path` parameter."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\ndbutils.fs.put(load_path + \"/load.py\", \n'''\nimport click\nimport mlflow\n\n@click.command()\n@click.option(\"--data_input_path\", default=\"/dbfs/mnt/training/airbnb/sf-listings/airbnb-cleaned-mlflow.csv\", type=str)\n@click.option(\"--train_path\", default=\"\", type=str)\ndef data_load(data_input_path, train_path):\n\n  with mlflow.start_run() as run:\n    # Log the data\n    mlflow.log_artifact(data_input_path, \"data-csv-dir\")\n  mlflow.projects.run(\n    uri= train_path,\n    parameters={ \"data_path\": data_input_path}\n    )\n\nif __name__ == \"__main__\":\n  data_load()\n\n'''.strip(), overwrite = True)\n\ndbutils.fs.ls(load_path)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Lastly, fill in the following single `mlflow.projects.run` call to directly run the loading data project which should then indirectly invoke the training code, all on the driver node of our Spark cluster."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\n\nmlflow.projects.run(load_path.replace(\"dbfs:\", \"/dbfs\"),\n  parameters={\n    \"data_input_path\": \"/dbfs/mnt/training/airbnb/sf-listings/airbnb-cleaned-mlflow.csv\",\n    \"train_path\": train_path.replace(\"dbfs:\", \"/dbfs\")\n})"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["Check that these logged runs also show up properly on the MLflow UI."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2019 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"03-Lab","notebookId":1121904905106286},"nbformat":4,"nbformat_minor":0}
