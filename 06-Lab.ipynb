{"cells":[{"cell_type":"markdown","source":["d-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 163px\">\n</div>"],"metadata":{}},{"cell_type":"markdown","source":["# Lab 6: Reading from Cosmos vs Reading from Parquet\n\n## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png) In this lab you:<br>\n - Configure and use an Azure Cosmos database\n - Read from a parquet file\n - Compare runtimes of using Cosmos and parquet"],"metadata":{}},{"cell_type":"code","source":["%run \"./../Includes/Classroom-Setup\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["## Configure and Use an Azure Cosmos Database"],"metadata":{}},{"cell_type":"markdown","source":["Run the following cell to configure a Cosmos database to read our airbnb predictions from."],"metadata":{}},{"cell_type":"code","source":["PrimaryRead = \"SidFEUCE2RA5qMYdUonLdwp4bAYW6Xj4R5Xdw4Bo7F4fkG9anp7IhjwEZc9wOvM4FJBU84efcupWZTrabFlinA==\" # Read only keys\nEndpoint = \"https://airbnbpredictions.documents.azure.com:443/\"\nCosmosDatabase =  \"predictions\"\nCosmosCollection = \"predictions\"\n\nif not PrimaryRead:\n  raise Exception(\"Don't forget to specify the cosmos keys in this cell.\")\n\ncosmosConfig = {\n  \"Endpoint\": Endpoint,\n  \"Masterkey\": PrimaryRead,\n  \"Database\": CosmosDatabase,\n  \"Collection\": CosmosCollection\n}"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["Create a Spark DataFrame to read from Cosmos DB to see its contents."],"metadata":{}},{"cell_type":"code","source":["cosmos_prediction_df = (spark.read\n    .format(\"com.microsoft.azure.cosmosdb.spark\")\n    .options(**cosmosConfig)\n    .load()\n   )\n \ndisplay(cosmos_prediction_df)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["This is the standard airbnb dataset with some additional metadata.\n\nBased off of the above code to create a DataFrame from Cosmos DB, fill in the `predict_cosmos(id)` function to read from Cosmos DB and return the predicted price (a float type) based on the column `id`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\nfrom pyspark.sql.functions import col\n\ndef predict_cosmos(id):\n  # read in df from Cosmos\n  prediction = (spark.read\n    .format(\"com.microsoft.azure.cosmosdb.spark\")\n    .options(**cosmosConfig)\n    .load()\n    .filter(col(\"id\") == id)\n    .select(\"prediction\")\n    .first()\n  )[0]\n  return prediction\n\nid_predict = \"7b22b1d3-c634-4bad-a854-17e0669aa685\"\np = predict_cosmos(id_predict)\n\nprint(p)\nassert type(p) == float, \" `predict_cosmos` should return 1 float type\""],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["## Reading from a Parquet File"],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\nSimilar to the previous cell, fill in the `predict_parquet(id)` function to return the prediction of row `id` from the parquet file stored at path `/mnt/training/airbnb/sf-listings/prediction.parquet`.\n\n<img alt=\"Hint\" title=\"Hint\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.3em\" src=\"https://files.training.databricks.com/static/images/icon-light-bulb.svg\"/>&nbsp;**Hint:** Load in a parquet file path using `spark.read.parquet`."],"metadata":{}},{"cell_type":"code","source":["# ANSWER\n\ndef predict_parquet(id):\n  prediction = (spark.read\n    .parquet(\"/mnt/training/airbnb/sf-listings/prediction.parquet\")\n    .filter(col(\"id\") == id)\n    .select(\"prediction\")\n    .first()\n  )[0]\n  return prediction\n\np = predict_parquet(id_predict)\nprint(p)\nassert type(p) == float, \" `predict_parquet` should return 1 float type\""],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["## Compare Runtimes of Cosmos and Parquet\n\nRun the following cells to look at the average time it takes to execute 5 different queries on from Cosmos versus a parquet file."],"metadata":{}},{"cell_type":"code","source":["num_queries = 5\n\nid_list = cosmos_prediction_df.limit(num_queries).select(\"id\").collect()\nids = [i[0] for i in id_list]\n\nids"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["%timeit -n3 [predict_cosmos(id) for id in ids]"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["%timeit -n3 [predict_parquet(id) for id in ids]"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":["-sandbox\nWhich performed better?  What are the trade-offs between using the two solutions in production?\n\n<img alt=\"Side Note\" title=\"Side Note\" style=\"vertical-align: text-bottom; position: relative; height:1.75em; top:0.05em; transform:rotate(15deg)\" src=\"https://files.training.databricks.com/static/images/icon-note.webp\"/> These results will depend in part on the load on Cosmos generated by the class."],"metadata":{}},{"cell_type":"markdown","source":["-sandbox\n&copy; 2019 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"http://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"http://help.databricks.com/\">Support</a>"],"metadata":{}}],"metadata":{"name":"06-Lab","notebookId":1121904905106378},"nbformat":4,"nbformat_minor":0}
